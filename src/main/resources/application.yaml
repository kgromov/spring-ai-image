spring:
  application:
    name: spring-ai-image
  ai:
    ollama:
      chat:
        model: llama3.2-vision
    # disable autoconfiguration on multiple LLMs
#    chat:
#      client:
#        enabled: false